{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916465d6",
   "metadata": {},
   "source": [
    "# ‚úÖ CU Percentile Heatmap: Prop AMM Compute Unit Analysis\n",
    "\n",
    "**Purpose**: Visualize worst-case Compute Unit consumption across all critical Prop AMM operations.\n",
    "\n",
    "**Why this matters (Feb 2026)**:\n",
    "- Solana has a hard CU limit per transaction (~1.4M CU, but effective safe limit much lower for high-frequency Prop AMMs)\n",
    "- Your `compute_swap` + update functions run thousands of times per slot\n",
    "- **Percentiles matter more than averages**: p99 and max = \"spike\" cases during volatility\n",
    "- If p99 CU > ~40k‚Äì50k, your function will **fail on-chain** during real traffic\n",
    "- Updates (Blind/Fast/Full) must stay very cheap (<100 CU) to spam frequently\n",
    "- Swaps on different curves show computational cost of your pricing logic\n",
    "\n",
    "**This visualization reveals**:\n",
    "- Which curve is safest for production (lowest p99 CU)\n",
    "- Whether `afterSwap` hooks or oracle updates are blowing the budget\n",
    "- Why edge might disappear on-chain: high p99 CU ‚Üí txs fail ‚Üí stale quotes ‚Üí contagion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c94d4",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c217896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set style for professional visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 9)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640047bb",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare CU Benchmark Data\n",
    "\n",
    "Your raw CU logs should be in a CSV format with at least two columns:\n",
    "- `operation` ‚Üí e.g. \"Swap Buy / Curve B\", \"FullUpdate / both-all\"\n",
    "- `cu` ‚Üí raw compute units consumed\n",
    "\n",
    "Update the path below to point to your CU benchmark CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022f1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your CU benchmark data path here\n",
    "# Update this path to point to your CU benchmark CSV file\n",
    "data_path = 'outputs/cu_benchmark_logs.csv'\n",
    "\n",
    "# Alternative paths to check if the above doesn't exist\n",
    "alternative_paths = [\n",
    "    'outputs/cu_logs.csv',\n",
    "    'cu_benchmark_logs.csv',\n",
    "    'cu_logs.csv'\n",
    "]\n",
    "\n",
    "# Find the actual path\n",
    "if not os.path.exists(data_path):\n",
    "    print(f\"‚ö†Ô∏è  Primary path not found: {data_path}\")\n",
    "    for alt in alternative_paths:\n",
    "        if os.path.exists(alt):\n",
    "            data_path = alt\n",
    "            print(f\"‚úì Using alternative path: {data_path}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  WARNING: CU benchmark CSV not found!\")\n",
    "        print(f\"   Please ensure your CU data is in one of these locations:\")\n",
    "        for path in [data_path] + alternative_paths:\n",
    "            print(f\"     - {path}\")\n",
    "\n",
    "# Load your raw CU benchmark data\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"‚úì Loaded CU benchmark data: {len(df)} rows\")\n",
    "    print(f\"\\nColumns: {list(df.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Could not find CU benchmark data at {data_path}\")\n",
    "    print(\"Please provide your CU benchmark CSV file and update the data_path variable above.\")\n",
    "    df = None\n",
    "\n",
    "# Make sure operation names match the image style\n",
    "if df is not None:\n",
    "    df['operation'] = df['operation'].str.strip()\n",
    "    print(f\"\\n‚úì Found {df['operation'].nunique()} unique operations:\")\n",
    "    print(df['operation'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e0297",
   "metadata": {},
   "source": [
    "## Step 3: Compute Percentile Statistics\n",
    "\n",
    "Calculate key percentiles for each operation type: min, p50, p75, p90, p95, p99, max.\n",
    "\n",
    "These percentiles reveal:\n",
    "- **min**: Best-case scenario (rarely relevant)\n",
    "- **p50**: Median‚Äîtypical case\n",
    "- **p75-p90**: Common spikes (important for normal operation)\n",
    "- **p95-p99**: Extreme spikes (critical for on-chain safety)\n",
    "- **max**: Absolute worst case (use with caution‚Äîmay be outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b05e0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # 1. Compute percentiles per operation\n",
    "    percentiles = [0, 0.50, 0.75, 0.90, 0.95, 0.99, 1.0]\n",
    "    labels = ['min', 'p50', 'p75', 'p90', 'p95', 'p99', 'max']\n",
    "\n",
    "    pivot = df.groupby('operation')['cu'].quantile(percentiles).unstack()\n",
    "    pivot.columns = labels\n",
    "\n",
    "    print(f\"‚úì Computed percentiles for {len(pivot)} operation types\\n\")\n",
    "    print(pivot)\n",
    "\n",
    "    # 2. Reorder rows exactly like your screenshot (if available in data)\n",
    "    # Update with any actual operation names from your data\n",
    "    desired_order = [\n",
    "        'BlindUpdate / blindupdate',\n",
    "        'FastUpdate / all',\n",
    "        'FullUpdate / oracle-only',\n",
    "        'FullUpdate / bid-all',\n",
    "        'FullUpdate / ask-all',\n",
    "        'FullUpdate / both-all',\n",
    "        'Swap Sell / Curve A',\n",
    "        'Swap Sell / Curve B',\n",
    "        'Swap Sell / Curve C',\n",
    "        'Swap Sell / mixed',\n",
    "        'Swap Buy / Curve A',\n",
    "        'Swap Buy / Curve B',\n",
    "        'Swap Buy / Curve C',\n",
    "        'Swap Buy / mixed'\n",
    "    ]\n",
    "\n",
    "    # Only include operations that actually exist in the data\n",
    "    available_order = [op for op in desired_order if op in pivot.index]\n",
    "    if available_order:\n",
    "        pivot = pivot.reindex(available_order)\n",
    "        print(f\"\\n‚úì Reordered to {len(available_order)} available operations\")\n",
    "    else:\n",
    "        print(f\"\\n‚ÑπÔ∏è  Could not reorder by desired names. Using data as-is.\")\n",
    "        print(f\"   Actual operation names in data: {list(pivot.index)}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping percentile computation (no data loaded)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc392f2",
   "metadata": {},
   "source": [
    "## Step 4: Create CU Percentile Heatmap\n",
    "\n",
    "Generate the professional YlOrRd heatmap visualization with annotations. \n",
    "\n",
    "**Color coding**:\n",
    "- **Yellow**: Safe zone (CU < 10k‚Äì15k)\n",
    "- **Orange**: Caution zone (CU 15k‚Äì30k)\n",
    "- **Dark Red**: Danger zone (CU > 30k‚Äì40k) ‚Äî likely to fail on-chain under real traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542812fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'pivot' in locals():\n",
    "    # Create output directories if they don't exist\n",
    "    output_dir = Path('outputs/images')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Create the heatmap\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    cmap = sns.color_palette(\"YlOrRd\", as_cmap=True)  # yellow ‚Üí orange ‚Üí dark red\n",
    "\n",
    "    heatmap = sns.heatmap(\n",
    "        pivot,\n",
    "        annot=True,\n",
    "        fmt=',.0f',\n",
    "        cmap=cmap,\n",
    "        linewidths=0.5,\n",
    "        linecolor='white',\n",
    "        cbar_kws={'label': 'Compute Units (CU)'},\n",
    "        ax=ax,\n",
    "        vmin=pivot.min().min(),\n",
    "        vmax=pivot.max().max()\n",
    "    )\n",
    "\n",
    "    plt.title('CU Percentile Heatmap\\nWorst-case Compute Cost per Operation (Critical for On-Chain Safety)', \n",
    "              fontsize=18, pad=20, fontweight='bold')\n",
    "    plt.xlabel('Percentile', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Operation Type', fontsize=14, fontweight='bold')\n",
    "\n",
    "    # Rotate labels for readability\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "\n",
    "    # 2. Highlight dangerous zones (optional ‚Äî red box on high values)\n",
    "    danger_threshold = 40000  # Adjust based on your safety limits\n",
    "    caution_threshold = 30000\n",
    "\n",
    "    for i in range(pivot.shape[0]):\n",
    "        for j in range(pivot.shape[1]):\n",
    "            value = pivot.iloc[i, j]\n",
    "            if value > danger_threshold:\n",
    "                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='darkred', lw=3))\n",
    "            elif value > caution_threshold:\n",
    "                ax.add_patch(plt.Rectangle((j, i), 1, 1, fill=False, edgecolor='red', lw=2))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 3. Save the figure\n",
    "    output_path = output_dir / 'cu_percentile_heatmap.png'\n",
    "    plt.savefig(output_path, dpi=400, bbox_inches='tight')\n",
    "    print(f\"‚úì Heatmap saved to: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüìä Heatmap generated successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot create heatmap (missing data or pivot table)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77442693",
   "metadata": {},
   "source": [
    "## Step 5: Identify Dangerous Operations\n",
    "\n",
    "Operations where p99 CU exceeds critical thresholds pose on-chain execution risks during real traffic conditions.\n",
    "\n",
    "**Safety guidelines** (Feb 2026):\n",
    "- **Safe (green)**: p99 < 20k CU\n",
    "- **Caution (yellow)**: p99 20k‚Äì35k CU\n",
    "- **Dangerous (red)**: p99 > 35k‚Äì40k CU ‚Üí likely transaction failures under load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d14725",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'pivot' in locals():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DANGEROUS OPERATIONS (p99 > 30k CU)\")\n",
    "    print(\"=\" * 80)\n",
    "    dangerous = pivot[pivot['p99'] > 30000][['p99', 'max']].sort_values('p99', ascending=False)\n",
    "    if len(dangerous) > 0:\n",
    "        print(dangerous)\n",
    "        print(f\"\\n‚ö†Ô∏è  {len(dangerous)} operation(s) exceed safe threshold!\")\n",
    "        print(\"   These are likely to fail on-chain during real traffic.\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No operations exceed 30k CU at p99 (good sign!)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CAUTION OPERATIONS (20k < p99 ‚â§ 30k CU)\")\n",
    "    print(\"=\" * 80)\n",
    "    caution = pivot[(pivot['p99'] > 20000) & (pivot['p99'] <= 30000)][['p99', 'max']].sort_values('p99', ascending=False)\n",
    "    if len(caution) > 0:\n",
    "        print(caution)\n",
    "        print(f\"\\n‚ö†Ô∏è  {len(caution)} operation(s) in caution zone\")\n",
    "        print(\"   Monitor closely‚Äîmay fail during extreme volatility.\")\n",
    "    else:\n",
    "        print(\"\\n‚úì No operations in caution zone (excellent!)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SAFE OPERATIONS (p99 ‚â§ 20k CU)\")\n",
    "    print(\"=\" * 80)\n",
    "    safe = pivot[pivot['p99'] <= 20000][['p99', 'max']]\n",
    "    print(f\"‚úì {len(safe)} operation(s) are safe for production\")\n",
    "    if len(safe) > 0:\n",
    "        print(safe.sort_values('p99', ascending=False))\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot analyze dangerous operations (missing data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81924840",
   "metadata": {},
   "source": [
    "## Step 6: Generate Performance Insights\n",
    "\n",
    "Extract key metrics and actionable insights for report generation and challenge submission optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'pivot' in locals():\n",
    "    print(\"=\" * 80)\n",
    "    print(\"KEY PERFORMANCE METRICS FOR PROP AMM CHALLENGE\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # 1. Cheapest update method (by p99)\n",
    "    update_ops = pivot.loc[pivot.index.str.contains('Update', case=False, na=False)]\n",
    "    if len(update_ops) > 0:\n",
    "        cheapest_update = update_ops['p99'].idxmin()\n",
    "        cheapest_cu = update_ops.loc[cheapest_update, 'p99']\n",
    "        print(f\"\\n‚úì Cheapest update method (p99): {cheapest_update}\")\n",
    "        print(f\"  CU cost: {cheapest_cu:,.0f} (p99), {update_ops.loc[cheapest_update, 'max']:,.0f} (max)\")\n",
    "\n",
    "    # 2. Most expensive swap operation (by p99)\n",
    "    swap_ops = pivot.loc[pivot.index.str.contains('Swap', case=False, na=False)]\n",
    "    if len(swap_ops) > 0:\n",
    "        most_expensive_swap = swap_ops['p99'].idxmax()\n",
    "        expensive_cu = swap_ops.loc[most_expensive_swap, 'p99']\n",
    "        print(f\"\\n‚ö†Ô∏è  Most expensive swap (p99): {most_expensive_swap}\")\n",
    "        print(f\"  CU cost: {expensive_cu:,.0f} (p99), {swap_ops.loc[most_expensive_swap, 'max']:,.0f} (max)\")\n",
    "\n",
    "    # 3. Curve comparison (if available)\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"CURVE COMPARISON (Buy/Sell Side p99 CU)\")\n",
    "    print(\"-\" * 80)\n",
    "    for curve in ['Curve A', 'Curve B', 'Curve C', 'mixed']:\n",
    "        curve_ops = pivot.loc[pivot.index.str.contains(curve, case=False, na=False)]\n",
    "        if len(curve_ops) > 0:\n",
    "            avg_p99 = curve_ops['p99'].mean()\n",
    "            print(f\"{curve:12s}: avg p99 = {avg_p99:,8.0f} CU\")\n",
    "            for op in curve_ops.index:\n",
    "                print(f\"       {op:50s}: {curve_ops.loc[op, 'p99']:8.0f} CU (p99)\")\n",
    "\n",
    "    # 4. Percentile progression analysis\n",
    "    print(\"\\n\" + \"-\" * 80)\n",
    "    print(\"PERCENTILE PROGRESSION (Global Statistics)\")\n",
    "    print(\"-\" * 80)\n",
    "    global_stats = pd.DataFrame({\n",
    "        'min': pivot['min'].min(),\n",
    "        'p50': pivot['p50'].mean(),\n",
    "        'p75': pivot['p75'].mean(),\n",
    "        'p90': pivot['p90'].mean(),\n",
    "        'p95': pivot['p95'].mean(),\n",
    "        'p99': pivot['p99'].mean(),\n",
    "        'max': pivot['max'].max()\n",
    "    }, index=['Global']).T\n",
    "    print(global_stats)\n",
    "\n",
    "    # 5. Summary for report\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY FOR CHALLENGE SUBMISSION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nüìä Total operations analyzed: {len(pivot)}\")\n",
    "    print(f\"üìä Operations in danger zone (p99 > 30k): {len(pivot[pivot['p99'] > 30000])}\")\n",
    "    print(f\"üìä Operations in safe zone (p99 ‚â§ 20k): {len(pivot[pivot['p99'] <= 20000])}\")\n",
    "    \n",
    "    # Calculate overall safety score\n",
    "    total_ops = len(pivot)\n",
    "    safe_ops = len(pivot[pivot['p99'] <= 20000])\n",
    "    safety_score = (safe_ops / total_ops * 100) if total_ops > 0 else 0\n",
    "    print(f\"\\nüéØ Safety Score: {safety_score:.1f}% ({safe_ops}/{total_ops} operations are safe)\")\n",
    "    \n",
    "    if safety_score >= 80:\n",
    "        print(\"   ‚úì EXCELLENT: Your Prop AMM is well-optimized for on-chain execution!\")\n",
    "    elif safety_score >= 50:\n",
    "        print(\"   ‚ö†Ô∏è  MODERATE: Good baseline, but some operations need optimization.\")\n",
    "    else:\n",
    "        print(\"   ‚ùå POOR: Significant optimization needed before mainnet deployment.\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot generate insights (missing data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be26b9",
   "metadata": {},
   "source": [
    "## Bonus: Export Results for Report Generation\n",
    "\n",
    "Save the percentile matrix and analysis results to CSV/JSON for easy inclusion in your challenge report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610514ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and 'pivot' in locals():\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    output_dir = Path('outputs')\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # 1. Export percentile matrix to CSV\n",
    "    csv_path = output_dir / 'cu_percentile_analysis.csv'\n",
    "    pivot.to_csv(csv_path)\n",
    "    print(f\"‚úì Exported percentile analysis to: {csv_path}\")\n",
    "    \n",
    "    # 2. Export summary statistics to JSON\n",
    "    summary_data = {\n",
    "        'total_operations': len(pivot),\n",
    "        'safe_operations': int(len(pivot[pivot['p99'] <= 20000])),\n",
    "        'caution_operations': int(len(pivot[(pivot['p99'] > 20000) & (pivot['p99'] <= 30000)])),\n",
    "        'dangerous_operations': int(len(pivot[pivot['p99'] > 30000])),\n",
    "        'global_p99_avg': float(pivot['p99'].mean()),\n",
    "        'global_p99_max': float(pivot['p99'].max()),\n",
    "        'global_p99_min': float(pivot['p99'].min()),\n",
    "        'operations': {\n",
    "            op: {\n",
    "                'min': float(pivot.loc[op, 'min']),\n",
    "                'p50': float(pivot.loc[op, 'p50']),\n",
    "                'p75': float(pivot.loc[op, 'p75']),\n",
    "                'p90': float(pivot.loc[op, 'p90']),\n",
    "                'p95': float(pivot.loc[op, 'p95']),\n",
    "                'p99': float(pivot.loc[op, 'p99']),\n",
    "                'max': float(pivot.loc[op, 'max']),\n",
    "                'risk_level': 'SAFE' if pivot.loc[op, 'p99'] <= 20000 else ('CAUTION' if pivot.loc[op, 'p99'] <= 30000 else 'DANGEROUS')\n",
    "            }\n",
    "            for op in pivot.index\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    json_path = output_dir / 'cu_percentile_analysis.json'\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(summary_data, f, indent=2)\n",
    "    print(f\"‚úì Exported summary stats to: {json_path}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All results exported successfully!\")\n",
    "    print(f\"\\nYou can now use these files in your challenge report:\")\n",
    "    print(f\"  - CSV (for spreadsheets): {csv_path}\")\n",
    "    print(f\"  - JSON (for dashboards): {json_path}\")\n",
    "    print(f\"  - PNG (for presentations): outputs/images/cu_percentile_heatmap.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot export results (missing data)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
