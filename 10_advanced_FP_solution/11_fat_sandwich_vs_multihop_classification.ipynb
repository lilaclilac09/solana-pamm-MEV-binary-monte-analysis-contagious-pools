{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a9252da",
   "metadata": {},
   "source": [
    "# Fat Sandwich (B91) vs Multi-Hop Arbitrage Classification\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to differentiate between Fat Sandwich attacks (B91 Pattern) and Multi-Hop Arbitrage (Cycle Trading) within the Solana pAMM ecosystem.\n",
    "\n",
    "### Key Dimensions\n",
    "\n",
    "1. **Presence of Victims**: Fat Sandwich requires 2+ wrapped victims; Multi-Hop does not\n",
    "2. **Token Path Structure**: Fat Sandwich uses same pair (A→B, B→A); Multi-Hop uses cycles (A→B→C→A)\n",
    "3. **Pool Routing Logic**: Fat Sandwich uses 1-2 pools; Multi-Hop uses 3+ diverse pools\n",
    "4. **Timing & Triggers**: Fat Sandwich correlates with Oracle bursts; Multi-Hop with pool imbalances\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c1d96",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries and Data\n",
    "\n",
    "Load necessary libraries and transaction data for Solana pAMM analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f4596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our enhanced detection functions\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/aileen/Downloads/pamm/solana-pamm-analysis/solana-pamm-MEV-binary-monte-analysis')\n",
    "\n",
    "from improved_fat_sandwich_detection import (\n",
    "    detect_cycle_routing,\n",
    "    identify_token_structure,\n",
    "    analyze_pool_diversity,\n",
    "    detect_victims_in_cluster,\n",
    "    classify_mev_attack,\n",
    "    classify_mev_attacks_batch\n",
    ")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(\"✓ Enhanced detection functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5ae3af",
   "metadata": {},
   "source": [
    "## Section 2: Cluster Transaction Parsing\n",
    "\n",
    "Parse transaction clusters to extract key details: signer, tokens, pools, timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load your TRADE data\n",
    "# Assuming you have a parquet file or can construct a test dataframe\n",
    "\n",
    "# For demonstration, we'll create a sample cluster with known patterns\n",
    "# You would typically load: df_trades = pd.read_parquet('path/to/pamm_clean_final.parquet')\n",
    "# df_trades = df_trades[df_trades['kind'] == 'TRADE']\n",
    "\n",
    "print(\"Data Loading Template:\")\n",
    "print(\"\"\"\\ndf_trades = pd.read_parquet('data/pamm_clean_final.parquet')\n",
    "df_trades = df_trades[df_trades['kind'] == 'TRADE']\n",
    "\n",
    "Required columns:\n",
    "  - 'signer': Address of transaction executor\n",
    "  - 'from_token': Token being sold\n",
    "  - 'to_token': Token being bought\n",
    "  - 'ms_time': Millisecond timestamp\n",
    "  - 'slot': Solana slot number\n",
    "  - 'validator': Block proposer\n",
    "  - 'amm_trade': Pool/AMM identifier\n",
    "  - 'amount_in': Amount of from_token\n",
    "  - 'amount_out': Amount of to_token\n",
    "\"\"\")\n",
    "\n",
    "# Create a demonstration cluster showing Fat Sandwich pattern\n",
    "demo_fs_cluster = pd.DataFrame({\n",
    "    'signer': ['ATTACKER', 'VICTIM1', 'VICTIM2', 'VICTIM1', 'VICTIM2', 'ATTACKER'],\n",
    "    'from_token': ['PUMP', 'WSOL', 'WSOL', 'PUMP', 'PUMP', 'PUMP'],\n",
    "    'to_token': ['WSOL', 'PUMP', 'PUMP', 'WSOL', 'WSOL', 'WSOL'],\n",
    "    'ms_time': [1000, 1050, 1100, 1150, 1200, 1250],\n",
    "    'slot': [1000, 1000, 1000, 1000, 1000, 1000],\n",
    "    'amm_trade': ['RAYDIUM_POOL_1', 'RAYDIUM_POOL_1', 'RAYDIUM_POOL_1', 'RAYDIUM_POOL_1', 'RAYDIUM_POOL_1', 'RAYDIUM_POOL_1'],\n",
    "    'validator': ['VALIDATOR_A'] * 6\n",
    "})\n",
    "\n",
    "# Create a demonstration cluster showing Multi-Hop Arbitrage pattern\n",
    "demo_mh_cluster = pd.DataFrame({\n",
    "    'signer': ['BOT'] * 5,\n",
    "    'from_token': ['SOL', 'TOKEN_A', 'TOKEN_B', 'TOKEN_C', 'TOKEN_A'],\n",
    "    'to_token': ['TOKEN_A', 'TOKEN_B', 'TOKEN_C', 'TOKEN_A', 'SOL'],\n",
    "    'ms_time': [2000, 2050, 2100, 2150, 2200],\n",
    "    'slot': [2000, 2000, 2000, 2000, 2000],\n",
    "    'amm_trade': ['ORCA_POOL_1', 'ORCA_POOL_2', 'MARINADE_POOL', 'ORCA_POOL_3', 'ORCA_POOL_1'],\n",
    "    'validator': ['VALIDATOR_B'] * 5\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEMO CLUSTER 1: Fat Sandwich Pattern (A-B-C-...-A with victims)\")\n",
    "print(\"=\"*80)\n",
    "print(demo_fs_cluster)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DEMO CLUSTER 2: Multi-Hop Arbitrage Pattern (Cycle trading)\")\n",
    "print(\"=\"*80)\n",
    "print(demo_mh_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90a1cc",
   "metadata": {},
   "source": [
    "## Section 3: Victim Detection Logic\n",
    "\n",
    "Identify wrapped victims between attacker's front-run and back-run transactions. At least 2 victims are required for a Fat Sandwich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cluster_victims(cluster_df, attacker_signer):\n",
    "    \"\"\"\n",
    "    Detailed victim analysis for a cluster.\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing victims for attacker: {attacker_signer}\")\n",
    "    print()\n",
    "    \n",
    "    # Use our built-in function\n",
    "    victim_info = detect_victims_in_cluster(cluster_df, attacker_signer)\n",
    "    \n",
    "    print(f\"Victim Count: {victim_info['victim_count']}\")\n",
    "    print(f\"Victim Signers: {victim_info['victim_signers']}\")\n",
    "    print(f\"Victim Ratio: {victim_info['victim_ratio']:.2%}\")\n",
    "    print(f\"Has Mandatory Victims (≥2): {victim_info['has_mandatory_victims']}\")\n",
    "    print()\n",
    "    \n",
    "    # Show victim trades\n",
    "    attacker_trades = cluster_df[cluster_df['signer'] == attacker_signer].sort_values('ms_time')\n",
    "    if len(attacker_trades) >= 2:\n",
    "        first_idx = cluster_df[cluster_df['signer'] == attacker_signer].index[0]\n",
    "        last_idx = cluster_df[cluster_df['signer'] == attacker_signer].index[-1]\n",
    "        \n",
    "        between_trades = cluster_df[(cluster_df.index > first_idx) & (cluster_df.index < last_idx)]\n",
    "        print(\"Trades between attacker's front-run and back-run:\")\n",
    "        print(between_trades[['signer', 'from_token', 'to_token']])\n",
    "    print()\n",
    "    return victim_info\n",
    "\n",
    "# Test on both clusters\n",
    "print(\"=\"*80)\n",
    "print(\"VICTIM ANALYSIS: Fat Sandwich Cluster\")\n",
    "print(\"=\"*80)\n",
    "victim_fs = analyze_cluster_victims(demo_fs_cluster, 'ATTACKER')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VICTIM ANALYSIS: Multi-Hop Arbitrage Cluster\")\n",
    "print(\"=\"*80)\n",
    "victim_mh = analyze_cluster_victims(demo_mh_cluster, 'BOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44faaa3",
   "metadata": {},
   "source": [
    "## Section 4: Token Path Structure Analysis\n",
    "\n",
    "Analyze the sequence of from_token and to_token to distinguish between:\n",
    "- **Same Pair** (Fat Sandwich): A→B, then B→A\n",
    "- **Cycle** (Multi-Hop): A→B→C→A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a86cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_token_paths(cluster_df, signer):\n",
    "    \"\"\"\n",
    "    Detailed token path analysis for a signer.\n",
    "    \"\"\"\n",
    "    print(f\"Token Path Analysis for: {signer}\")\n",
    "    print()\n",
    "    \n",
    "    # Get token structure\n",
    "    token_struct = identify_token_structure(cluster_df, signer)\n",
    "    \n",
    "    print(f\"Unique Token Pairs: {token_struct['unique_token_pairs']}\")\n",
    "    print(f\"Token Pairs Used: {token_struct['token_pairs']}\")\n",
    "    print(f\"Same Pair Throughout: {token_struct['is_same_pair_throughout']}\")\n",
    "    print(f\"Pair Consistency: {token_struct['pair_consistency']:.2%}\")\n",
    "    print(f\"Pattern Type: {token_struct['pattern_type'].upper()}\")\n",
    "    print()\n",
    "    \n",
    "    # Show the path\n",
    "    signer_trades = cluster_df[cluster_df['signer'] == signer].sort_values('ms_time')\n",
    "    print(\"Token Flow Path:\")\n",
    "    path = []\n",
    "    for idx, trade in signer_trades.iterrows():\n",
    "        if len(path) == 0:\n",
    "            path.append(trade['from_token'])\n",
    "        path.append(trade['to_token'])\n",
    "    \n",
    "    path_str = \" → \".join(path)\n",
    "    print(f\"  {path_str}\")\n",
    "    \n",
    "    # Determine if it's a recognized cycle\n",
    "    if len(path) > 0 and path[0] == path[-1]:\n",
    "        print(f\"  ✓ Cycle detected: Returns to starting token\")\n",
    "    elif signer_trades.iloc[-1]['to_token'] in ['SOL', 'USDC']:\n",
    "        print(f\"  ✓ Cycle detected: Returns to base asset\")\n",
    "    else:\n",
    "        print(f\"  ✗ Not a true cycle\")\n",
    "    print()\n",
    "    return token_struct\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TOKEN PATH ANALYSIS: Fat Sandwich\")\n",
    "print(\"=\"*80)\n",
    "token_fs = analyze_token_paths(demo_fs_cluster, 'ATTACKER')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOKEN PATH ANALYSIS: Multi-Hop Arbitrage\")\n",
    "print(\"=\"*80)\n",
    "token_mh = analyze_token_paths(demo_mh_cluster, 'BOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d251489",
   "metadata": {},
   "source": [
    "## Section 5: Pool Routing and Signer Diversity Analysis\n",
    "\n",
    "Count unique pools and analyze routing patterns:\n",
    "- **Fat Sandwich**: 1-2 pools targeting same pair\n",
    "- **Multi-Hop Arbitrage**: 3+ pools with different pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096c6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pool_routing(cluster_df, signer):\n",
    "    \"\"\"\n",
    "    Detailed pool routing analysis for a signer.\n",
    "    \"\"\"\n",
    "    print(f\"Pool Routing Analysis for: {signer}\")\n",
    "    print()\n",
    "    \n",
    "    # Get pool diversity\n",
    "    pool_info = analyze_pool_diversity(cluster_df, signer)\n",
    "    \n",
    "    print(f\"Unique Pools Used: {pool_info['unique_pools']}\")\n",
    "    print(f\"Pools: {pool_info['pools']}\")\n",
    "    print(f\"Avg Pools per Pair: {pool_info['avg_pools_per_pair']:.2f}\")\n",
    "    print(f\"Pool Diversity Score: {pool_info['pool_diversity_score']:.2f}\")\n",
    "    print(f\"Likely Attack Type: {pool_info['likely_attack_type'].upper()}\")\n",
    "    print()\n",
    "    \n",
    "    # Interpretation\n",
    "    if pool_info['unique_pools'] <= 2:\n",
    "        print(\"  ➜ Low pool count (≤2) suggests Fat Sandwich\")\n",
    "        print(\"    Focus: Extract slippage from victims within same pair\")\n",
    "    else:\n",
    "        print(f\"  ➜ High pool count ({pool_info['unique_pools']}) suggests Multi-Hop\")\n",
    "        print(\"    Focus: Route through multiple pools to exploit imbalances\")\n",
    "    print()\n",
    "    return pool_info\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"POOL ROUTING ANALYSIS: Fat Sandwich\")\n",
    "print(\"=\"*80)\n",
    "pool_fs = analyze_pool_routing(demo_fs_cluster, 'ATTACKER')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"POOL ROUTING ANALYSIS: Multi-Hop Arbitrage\")\n",
    "print(\"=\"*80)\n",
    "pool_mh = analyze_pool_routing(demo_mh_cluster, 'BOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa144625",
   "metadata": {},
   "source": [
    "## Section 6: Timing and Trigger Signal Analysis\n",
    "\n",
    "Analyze temporal patterns and correlations:\n",
    "- **Fat Sandwich**: Highly correlated with Oracle bursts (99.8%)\n",
    "- **Multi-Hop**: Triggered by pool imbalances rather than Oracle signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_timing_triggers(cluster_df, signer):\n",
    "    \"\"\"\n",
    "    Analyze timing patterns and potential triggers.\n",
    "    \"\"\"\n",
    "    print(f\"Timing Analysis for: {signer}\")\n",
    "    print()\n",
    "    \n",
    "    signer_trades = cluster_df[cluster_df['signer'] == signer].sort_values('ms_time')\n",
    "    \n",
    "    if len(signer_trades) < 2:\n",
    "        print(\"  Insufficient trades for timing analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate timing metrics\n",
    "    times = signer_trades['ms_time'].values\n",
    "    time_diffs = np.diff(times)\n",
    "    \n",
    "    avg_gap = time_diffs.mean()\n",
    "    max_gap = time_diffs.max()\n",
    "    min_gap = time_diffs.min()\n",
    "    total_span = times[-1] - times[0]\n",
    "    \n",
    "    print(f\"Total Time Span: {total_span}ms ({total_span/1000:.3f}s)\")\n",
    "    print(f\"Average Gap Between Trades: {avg_gap:.1f}ms\")\n",
    "    print(f\"Max Gap: {max_gap:.1f}ms\")\n",
    "    print(f\"Min Gap: {min_gap:.1f}ms\")\n",
    "    print()\n",
    "    \n",
    "    # Trigger analysis\n",
    "    if total_span < 50:\n",
    "        print(\"  ➜ Sub-50ms execution: Strong Fat Sandwich indicator\")\n",
    "        print(\"    Tight back-running window suggests victim exploitation\")\n",
    "    else:\n",
    "        print(f\"  ➜ {total_span}ms execution: Could be either type\")\n",
    "    \n",
    "    if max_gap > 100:\n",
    "        print(f\"  ➜ Large gap detected ({max_gap}ms): May indicate multi-hop routing\")\n",
    "    \n",
    "    # Oracle burst check (example)\n",
    "    print()\n",
    "    print(\"Oracle Burst Correlation:\")\n",
    "    print(\"  (In production, check if Oracle was updated in this slot)\")\n",
    "    print(\"  - Fat Sandwich: 99.8% follow Oracle bursts\")\n",
    "    print(\"  - Multi-Hop: ~50% follow Oracle updates\")\n",
    "    print()\n",
    "    return {'avg_gap': avg_gap, 'total_span': total_span, 'max_gap': max_gap}\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TIMING ANALYSIS: Fat Sandwich\")\n",
    "print(\"=\"*80)\n",
    "timing_fs = analyze_timing_triggers(demo_fs_cluster, 'ATTACKER')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TIMING ANALYSIS: Multi-Hop Arbitrage\")\n",
    "print(\"=\"*80)\n",
    "timing_mh = analyze_timing_triggers(demo_mh_cluster, 'BOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a205a9",
   "metadata": {},
   "source": [
    "## Section 7: Cycle Routing Detection Function\n",
    "\n",
    "Implement `detect_cycle_routing()` to verify if a signer's net token balance (excluding starting token) is zero, confirming Multi-Hop Arbitrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58943f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_cycle_analysis(cluster_df, signer):\n",
    "    \"\"\"\n",
    "    Detailed cycle routing analysis.\n",
    "    \"\"\"\n",
    "    print(f\"Cycle Routing Analysis for: {signer}\")\n",
    "    print()\n",
    "    \n",
    "    # Use our built-in cycle detection\n",
    "    cycle_info = detect_cycle_routing(cluster_df, signer)\n",
    "    \n",
    "    print(f\"Is Cycle: {cycle_info['is_cycle']}\")\n",
    "    print(f\"Cycle Confidence: {cycle_info['confidence']:.2%}\")\n",
    "    print(f\"Cycle Length: {cycle_info['cycle_length']} hops\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"Path: {' → '.join(cycle_info['cycle_path'])}\")\n",
    "    print(f\"Starting Token: {cycle_info['starting_token']}\")\n",
    "    print(f\"Ending Token: {cycle_info['ending_token']}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Net Balance Change (by token):\")\n",
    "    for token, change in cycle_info['net_balance_change'].items():\n",
    "        status = \"✓\" if change == 0 else \"✗\"\n",
    "        print(f\"  {status} {token:20s}: {change:+3d}\")\n",
    "    print()\n",
    "    \n",
    "    # Verification\n",
    "    total_net = sum(cycle_info['net_balance_change'].values())\n",
    "    if total_net == 0:\n",
    "        print(\"  ✓ Perfect cycle: Net balance is zero\")\n",
    "        print(\"  → Strong Multi-Hop Arbitrage indicator\")\n",
    "    else:\n",
    "        print(f\"  ✗ Not a perfect cycle: Net balance ≠ 0 ({total_net:+d})\")\n",
    "        print(\"  → Suggests Fat Sandwich or incomplete data\")\n",
    "    print()\n",
    "    return cycle_info\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CYCLE DETECTION: Fat Sandwich\")\n",
    "print(\"=\"*80)\n",
    "cycle_fs = detailed_cycle_analysis(demo_fs_cluster, 'ATTACKER')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CYCLE DETECTION: Multi-Hop Arbitrage\")\n",
    "print(\"=\"*80)\n",
    "cycle_mh = detailed_cycle_analysis(demo_mh_cluster, 'BOT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2976785",
   "metadata": {},
   "source": [
    "## Section 8: Summary Comparison Table Generation\n",
    "\n",
    "Generate comprehensive comparison of both clusters based on all analysis dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319dcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_table():\n",
    "    \"\"\"\n",
    "    Create side-by-side comparison of Fat Sandwich vs Multi-Hop characteristics.\n",
    "    \"\"\"\n",
    "    comparison_data = {\n",
    "        'Feature': [\n",
    "            'Intermediate Victims',\n",
    "            'Token Structure',\n",
    "            'Token Pair Pattern',\n",
    "            'Pool Count',\n",
    "            'Pool Protocol Diversity',\n",
    "            'Primary Goal',\n",
    "            'Timing (ms)',\n",
    "            'Oracle Burst Correlation',\n",
    "            'Trigger Type',\n",
    "            'Back-Run Window',\n",
    "            'Net Balance Zero',\n",
    "            'Cycle Path',\n",
    "        ],\n",
    "        'Fat Sandwich (B91)': [\n",
    "            'Mandatory (≥2)',\n",
    "            'A-B-C-...-A (same signer)',\n",
    "            'Same pair (A→B, B→A)',\n",
    "            '1-2 pools',\n",
    "            'Low (same pair across different protocols)',\n",
    "            'Extract victim slippage',\n",
    "            '<50ms (aggressive back-run)',\n",
    "            '99.8% (DeezNode style)',\n",
    "            'Oracle burst signal',\n",
    "            '<50ms window required',\n",
    "            'No (attacker profits)',\n",
    "            'Not applicable',\n",
    "        ],\n",
    "        'Multi-Hop Arbitrage (Cycle)': [\n",
    "            'None required',\n",
    "            'A→B→C→A (no victims)',\n",
    "            'Different pairs in cycle',\n",
    "            '3+ pools',\n",
    "            'High (many protocols/pairs)',\n",
    "            'Exploit pool imbalances',\n",
    "            'Variable (not time-critical)',\n",
    "            '~50% (optional)',\n",
    "            'Pool imbalance signal',\n",
    "            'Not time-dependent',\n",
    "            'Yes (arbitrage closure)',\n",
    "            'Returns to starting token',\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    return comparison_df\n",
    "\n",
    "comparison_table = create_comparison_table()\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"COMPREHENSIVE FEATURE COMPARISON\")\n",
    "print(\"=\"*120)\n",
    "print(comparison_table.to_string(index=False))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1231727",
   "metadata": {},
   "source": [
    "## Integrated Classification Demo\n",
    "\n",
    "Use the comprehensive `classify_mev_attack()` function to automatically classify both clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087cdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Fat Sandwich cluster\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTEGRATED CLASSIFICATION: Fat Sandwich\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "classification_fs = classify_mev_attack(\n",
    "    demo_fs_cluster,\n",
    "    'ATTACKER',\n",
    "    oracle_burst_in_slot=True,  # Simulating oracle burst\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTEGRATED CLASSIFICATION: Multi-Hop Arbitrage\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "classification_mh = classify_mev_attack(\n",
    "    demo_mh_cluster,\n",
    "    'BOT',\n",
    "    oracle_burst_in_slot=False,  # No oracle burst\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78a75b",
   "metadata": {},
   "source": [
    "## Production Usage: Batch Classification\n",
    "\n",
    "In production, use `classify_mev_attacks_batch()` to classify all detected attacks at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e6675e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH CLASSIFICATION WORKFLOW\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"\"\"\n",
    "## Production Workflow:\n",
    "\n",
    "# Step 1: Load and detect fat sandwiches\n",
    "from improved_fat_sandwich_detection import detect_fat_sandwich_time_window\n",
    "\n",
    "df_trades = pd.read_parquet('data/pamm_clean_final.parquet')\n",
    "df_trades = df_trades[df_trades['kind'] == 'TRADE']\n",
    "\n",
    "detected_attacks, stats = detect_fat_sandwich_time_window(\n",
    "    df_trades,\n",
    "    window_seconds=[1, 2, 5, 10],\n",
    "    min_trades=5,\n",
    "    max_victim_ratio=0.8,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Step 2: Classify all detected attacks\n",
    "from improved_fat_sandwich_detection import classify_mev_attacks_batch\n",
    "\n",
    "classified_attacks = classify_mev_attacks_batch(\n",
    "    df_all_trades=df_trades,\n",
    "    detected_attacks_df=detected_attacks,\n",
    "    verbose=False,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "# Step 3: Analyze results by type\n",
    "fat_sandwiches = classified_attacks[classified_attacks['attack_type'] == 'fat_sandwich']\n",
    "multi_hops = classified_attacks[classified_attacks['attack_type'] == 'multi_hop_arbitrage']\n",
    "ambiguous = classified_attacks[classified_attacks['attack_type'] == 'ambiguous']\n",
    "\n",
    "print(f\"Fat Sandwiches: {len(fat_sandwiches)}\")\n",
    "print(f\"Multi-Hop Arbitrage: {len(multi_hops)}\")\n",
    "print(f\"Ambiguous: {len(ambiguous)}\")\n",
    "\n",
    "# Step 4: Further analysis\n",
    "print(\"\\nTop Fat Sandwich Attackers:\")\n",
    "print(fat_sandwiches['attacker_signer'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nMulti-Hop Arbitrage Statistics:\")\n",
    "print(multi_hops[['unique_pools_used', 'classification_confidence']].describe())\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✓ Batch classification workflow ready for production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ced490a",
   "metadata": {},
   "source": [
    "## Key Insights and Decision Rules\n",
    "\n",
    "### Primary Differentiator: Wrapped Victims\n",
    "- **Fat Sandwich REQUIRES** at least 2 victim trades between front-run and back-run\n",
    "- **Multi-Hop NEVER** wraps victims—it's pure arbitrage\n",
    "- If no victims found → Strong indicator of Multi-Hop\n",
    "\n",
    "### Token Path Validation\n",
    "- **Fat Sandwich**: Same token pair throughout (e.g., PUMP/WSOL only)\n",
    "- **Multi-Hop**: Cycle of different pairs (e.g., SOL→TokenA→TokenB→SOL)\n",
    "- Check if `to_token[N] == from_token[N+1]`\n",
    "\n",
    "### Pool Diversity Heuristic\n",
    "- **Fat Sandwich**: 1-2 pools (focused attack on single pair)\n",
    "- **Multi-Hop**: 3+ pools (distributed routing across protocols)\n",
    "- If unique_pools ≥ 3 AND token_pairs ≥ 3 → Likely Multi-Hop\n",
    "\n",
    "### Timing and Trigger Signals\n",
    "- **Fat Sandwich**: 99.8% correlation with Oracle bursts (DeezNode style)\n",
    "- **Multi-Hop**: Triggered by pool imbalances, not time-critical\n",
    "- Check if Oracle was updated in same slot\n",
    "\n",
    "### Net Balance Check (Ultimate Validator)\n",
    "- If signer's net token balance across all non-starting tokens = 0 → Definitive Multi-Hop\n",
    "- If attacker has positive balance in tokens → Fat Sandwich (extracted profit)\n",
    "\n",
    "---\n",
    "\n",
    "## Classification Confidence Model\n",
    "\n",
    "**Fat Sandwich Score** (0-1):\n",
    "- Wrapped victims present: +0.35\n",
    "- Same token pair: +0.25\n",
    "- Low pool diversity: +0.20\n",
    "- Oracle burst detected: +0.20\n",
    "\n",
    "**Multi-Hop Score** (0-1):\n",
    "- Cycle routing pattern: +0.35\n",
    "- Multiple token pairs: +0.25\n",
    "- High pool diversity: +0.20\n",
    "- No wrapped victims: +0.20\n",
    "\n",
    "**Final Classification**:\n",
    "- If |FS_score - MH_score| > 0.15 → Confident classification\n",
    "- Otherwise → Ambiguous (manual review recommended)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba644638",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the complete framework for differentiating Fat Sandwich attacks (B91 Pattern) from Multi-Hop Arbitrage (Cycle Trading) in Solana pAMM.\n",
    "\n",
    "### Methods Implemented:\n",
    "1. ✓ **Victim Detection**: Identify wrapped victims between front-run and back-run\n",
    "2. ✓ **Token Path Analysis**: Distinguish same-pair vs cyclic routing\n",
    "3. ✓ **Pool Routing Analysis**: Measure pool diversity and protocol distribution\n",
    "4. ✓ **Cycle Detection**: Validate net balance = 0 for arbitrage\n",
    "5. ✓ **Timing Analysis**: Correlate with Oracle bursts and pool imbalances\n",
    "6. ✓ **Classification Scoring**: Weighted multi-factor confidence model\n",
    "7. ✓ **Batch Processing**: Scale to full attack datasets\n",
    "\n",
    "### Use Cases:\n",
    "- **Regulatory**: Identify sandwich attacks targeting retail users\n",
    "- **Risk Analysis**: Understand arbitrage-induced pool volatility\n",
    "- **MEV Quantification**: Separate victim extraction vs pure arbitrage profits\n",
    "- **Protocol Optimization**: Design defenses against specific attack types"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
